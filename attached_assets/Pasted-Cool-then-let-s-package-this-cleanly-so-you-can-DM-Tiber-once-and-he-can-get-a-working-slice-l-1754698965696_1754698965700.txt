Cool â€” then letâ€™s **package this cleanly** so you can DM Tiber once and he can get a working slice live tonight.

# What to send Tiber (MVP first, then expand)

## ðŸŸ¢ MVP (ship tonight)

**Goal:** Produce `warehouse/2024_weekly.jsonl` with core stats + depth charts.
**Files to send him:**

1. `scripts/collect_weekly_core.py`
2. `scripts/collect_depth.py`
3. `scripts/stage_and_merge.py` (the one I gave you)
4. `scripts/run_pipeline.sh`

**Why this MVP:** no weird deps (snaps/injuries), just nflfastR + nflverse â†’ merged weekly file your site can read.

## ðŸŸ¡ Later add-ons (tomorrow)

* `scripts/collect_snaps.py` (usage/snap%)
* `scripts/collect_injuries.py` (RSS seed)
* `scripts/collect_elo.py` (team context)

---

# Paste this to Tiber (ready-to-forward)

**Subject:** OTC Redraft 2025 â€“ MVP pipeline (build this)

**Message:**

> Youâ€™re in *On The Clock* mode. Build a minimal nightly pipeline that outputs `warehouse/2024_weekly.jsonl` in JSONL format (one row per `player_id, season, week, team`).
>
> **Steps:**
>
> 1. Create folders: `raw/2024`, `staging`, `warehouse`, `scripts`.
> 2. Add these scripts (use the exact code I provide):
>
>    * `scripts/collect_weekly_core.py` (nflfastR weekly)
>    * `scripts/collect_depth.py` (nflverse weekly depth)
>    * `scripts/stage_and_merge.py` (normalize + join)
>    * `scripts/run_pipeline.sh` (orchestrates all)
> 3. Run `bash scripts/run_pipeline.sh`.
>
> **Success criteria:**
>
> * Files created:
>
>   * `raw/2024/stats_weekly.jsonl`
>   * `raw/2024/depth_weekly.jsonl`
>   * `staging/weekly_staging.jsonl`
>   * `warehouse/2024_weekly.jsonl`
> * Print a 5-row preview to stdout from the merge script.
> * JSONL rows must include these fields where available:
>   `player_id, season, week, team, position, routes, targets, air_yards, receptions, rushing_att (if any), fantasy_ppr, depth_rank`.
> * Use `null` for missing values (donâ€™t force zeros).
>
> **Notes:**
>
> * Standardize team codes (e.g., JAXâ†’JAC) and ensure `gsis_id â†’ player_id` mapping is applied.
> * Keep everything 2024 for MVP; weâ€™ll expand seasons and add snaps/injuries/context next.
>
> When done, reply with row count, first 5 rows, and any anomalies you had to normalize.

---

# The code youâ€™ll attach

* I already wrote `stage_and_merge.py`.
* Use the two collectors I gave you for **weekly core** and **depth** (theyâ€™re short).
* The `run_pipeline.sh` is just:

```bash
set -euo pipefail
python scripts/collect_weekly_core.py
python scripts/collect_depth.py
python scripts/stage_and_merge.py
```

Thatâ€™s it. Send that block + the three scripts. Once Tiber confirms the warehouse file is landing, we bolt on snaps/injuries/elo and flip the site to read from it.
