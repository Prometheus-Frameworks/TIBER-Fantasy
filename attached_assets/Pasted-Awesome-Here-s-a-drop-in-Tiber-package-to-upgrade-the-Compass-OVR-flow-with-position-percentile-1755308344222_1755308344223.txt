Awesome. Here’s a **drop-in Tiber package** to upgrade the Compass/OVR flow with position-percentiles, volume floors, and a **/players/hot-list** endpoint. It assumes your backend is FastAPI + pandas-ish ingestion (same vibe as Grok’s service). If you’re on Node, I can port it.

---

# 0) Install deps

```bash
pip install fastapi uvicorn pydantic pandas numpy
```

---

# 1) helpers.py

```python
# helpers.py
from __future__ import annotations
import numpy as np
import pandas as pd

# ---- position-aware percentiles ----
def pos_percentile(s: pd.Series, group: pd.Series) -> pd.Series:
    # returns 0..1 percentile per position group
    return s.groupby(group).rank(pct=True)

# ---- volume floors (avoid junk samples) ----
VOLUME_FLOORS = {
    "WR": {"routes": 12, "carries": 0},
    "RB": {"routes": 10, "carries": 8},
    "TE": {"routes": 12, "carries": 0},
}

def meets_volume_floor(df: pd.DataFrame) -> pd.Series:
    pos = df["pos"]
    routes_ok = df["routes"].fillna(0) >= pos.map(lambda p: VOLUME_FLOORS.get(p, {}).get("routes", 0))
    carries_ok = df["carries"].fillna(0) >= pos.map(lambda p: VOLUME_FLOORS.get(p, {}).get("carries", 0))
    # RB can qualify with either routes or carries; WR/TE require routes
    is_rb = (pos == "RB")
    return np.where(is_rb, routes_ok | carries_ok, routes_ok)

# ---- percentile thresholds (dynamic by position) ----
PCT_THRESHOLDS = {
    "elite_ovr": 0.90,
    "north": 0.85,
    "east": 0.75,
    "south_low": 0.25,  # lower is safer
    "west": 0.70,
}

# ---- big thresholds from weekly_change_ranges.csv (optional) ----
def load_change_ranges(path: str) -> pd.DataFrame:
    # columns expected:
    # pos, metric, mean_delta, median_delta, p75_delta, p90_delta, p95_delta, max_observed_delta,
    # small_change_threshold, medium_change_threshold, big_change_threshold
    return pd.read_csv(path)

def big_threshold(change_df: pd.DataFrame, pos: str, metric: str) -> float:
    row = change_df[(change_df.pos == pos) & (change_df.metric == metric)]
    if row.empty:
        # sensible default if absent
        defaults = {("WR","delta_routes_pct"):0.12, ("WR","delta_snap_pp"):10,
                    ("RB","delta_carry_share"):0.15, ("RB","delta_route_share"):0.10,
                    ("TE","delta_routes_pct"):0.10}
        return defaults.get((pos, metric), 0.10)
    v = row.iloc[0]["big_change_threshold"]
    try:
        return float(v)
    except Exception:
        return 0.10

# ---- risk halver for questionable tags (optional) ----
def apply_injury_halver(df: pd.DataFrame, delta_col: str, status_col: str = "status") -> pd.Series:
    # If status in {Q, DTD, LP}, halve positive delta this week
    status = df.get(status_col, pd.Series(index=df.index, dtype=str)).fillna("")
    factor = np.where(status.isin(["Q","DTD","LP","Questionable","Limited"]), 0.5, 1.0)
    return df[delta_col] * factor
```

---

# 2) models.py (schemas for responses)

```python
# models.py
from pydantic import BaseModel
from typing import Dict, List, Optional

class PlayerCompass(BaseModel):
    north: int
    east: int
    south: int
    west: int

class PlayerHealth(BaseModel):
    player_id: str
    name: str
    team: str
    pos: str
    base_ovr: int
    current_ovr: int
    weekly_change: int
    active_deltas: Dict[str, Dict[str, int]]  # {"Usage":{"snap_share":+2}, ...}
    last_update: str

class HealthResponse(BaseModel):
    week: str
    model_version: str
    inputs_version: str
    players: List[PlayerHealth]

class HotListItem(BaseModel):
    player_id: str
    name: str
    team: str
    pos: str
    current_ovr: int
    base_ovr: int
    delta_total: int
    compass: PlayerCompass
    reasons: List[str]
    confidence: str

class HotListResponse(BaseModel):
    week: str
    bucket: str
    criteria: Dict[str, str]
    model_version: str
    inputs_version: str
    players: List[HotListItem]
```

---

# 3) hotlist.py (router)

```python
# hotlist.py
from __future__ import annotations
from fastapi import APIRouter, Query
from typing import Optional
import pandas as pd
from helpers import pos_percentile, meets_volume_floor, PCT_THRESHOLDS, big_threshold, load_change_ranges
from models import HotListResponse, HotListItem, PlayerCompass

router = APIRouter()

# Expect a weekly dataframe already in memory or from cache:
# columns needed per player-week:
# player_id, name, team, pos, week, base_ovr, current_ovr, weekly_change,
# north, east, south, west, routes, carries, delta_snap_pp, delta_routes_pct,
# delta_carry_share, delta_route_share, reasons(list/json), confidence
DF_WEEKLY: Optional[pd.DataFrame] = None
CHANGE_RANGES: Optional[pd.DataFrame] = None
META = {"week":"", "model_version":"", "inputs_version":""}

def set_weekly_context(df_weekly: pd.DataFrame, change_ranges: pd.DataFrame, week: str, model_version: str, inputs_version: str):
    global DF_WEEKLY, CHANGE_RANGES, META
    DF_WEEKLY = df_weekly.copy()
    CHANGE_RANGES = change_ranges
    META = {"week":week, "model_version":model_version, "inputs_version":inputs_version}

def _with_percentiles(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["ovr_pct"]   = pos_percentile(df["current_ovr"], df["pos"])
    df["north_pct"] = pos_percentile(df["north"], df["pos"])
    df["east_pct"]  = pos_percentile(df["east"], df["pos"])
    df["south_pct"] = pos_percentile(df["south"], df["pos"])  # lower is safer; we invert later when filtering
    df["west_pct"]  = pos_percentile(df["west"], df["pos"])
    df["ovr_vs_base"] = df["current_ovr"] - df["base_ovr"]
    df["vol_ok"] = meets_volume_floor(df)
    return df

def _serialize_rows(rows: pd.DataFrame) -> list[HotListItem]:
    out = []
    for _, r in rows.iterrows():
        reasons = r.get("reasons", [])
        if isinstance(reasons, str):
            # could be comma-joined; be lenient
            reasons = [x.strip() for x in reasons.split(",") if x.strip()]
        item = HotListItem(
            player_id=r.player_id, name=r.name, team=r.team, pos=r.pos,
            current_ovr=int(r.current_ovr), base_ovr=int(r.base_ovr),
            delta_total=int(r.current_ovr - r.base_ovr),
            compass=PlayerCompass(north=int(r.north), east=int(r.east), south=int(r.south), west=int(r.west)),
            reasons=reasons[:3] if reasons else [],
            confidence=str(r.get("confidence","med")),
        )
        out.append(item)
    return out

@router.get("/players/hot-list", response_model=HotListResponse)
def hot_list(bucket: str = Query(..., pattern="^(risers|elite|usage_surge|value)$"),
             pos: Optional[str] = Query(None, pattern="^(WR|RB|TE)$"),
             limit: int = 25):
    assert DF_WEEKLY is not None, "Weekly dataframe not set in context"
    df = DF_WEEKLY if pos is None else DF_WEEKLY[DF_WEEKLY.pos == pos]
    df = _with_percentiles(df)

    if bucket == "elite":
        sel = (
            (df["ovr_pct"]   >= PCT_THRESHOLDS["elite_ovr"]) &
            (df["north_pct"] >= PCT_THRESHOLDS["north"]) &
            (df["east_pct"]  >= PCT_THRESHOLDS["east"]) &
            (df["south_pct"] <= PCT_THRESHOLDS["south_low"]) &  # lower is safer
            (df["west_pct"]  >= PCT_THRESHOLDS["west"]) &
            (df["vol_ok"])
        )
        out = df[sel].sort_values(["pos","current_ovr"], ascending=[True, False])

    elif bucket == "risers":
        # require persistence_weeks >= 2 if available; else fall back to ovr_vs_base + volume
        has_persist = "persistence_weeks" in df.columns
        sel = (
            (df["ovr_vs_base"] >= 5) &
            (df["vol_ok"]) &
            (df["persistence_weeks"] >= 2 if has_persist else True)
        )
        out = df[sel].sort_values(["pos","ovr_vs_base","current_ovr"], ascending=[True, False, False])

    elif bucket == "usage_surge":
        # use big thresholds table if present
        if CHANGE_RANGES is not None:
            # mark rows that exceed a big threshold for the metric overall
            def exceeds(row):
                p = row["pos"]
                r_big = big_threshold(CHANGE_RANGES, p, "delta_routes_pct")
                s_big = big_threshold(CHANGE_RANGES, p, "delta_snap_pp")
                return (row.get("delta_routes_pct",0) >= r_big) or (row.get("delta_snap_pp",0) >= s_big)
            mask = df.apply(exceeds, axis=1)
        else:
            mask = (df.get("delta_routes_pct",0) >= 0.12) | (df.get("delta_snap_pp",0) >= 10)

        out = df[mask & df["vol_ok"]].sort_values(["pos","delta_routes_pct","delta_snap_pp"], ascending=[True, False, False])

    else:  # value
        # needs ADP percentile; expect columns adp_pct (0..1). If missing, return empty.
        if "adp_pct" not in df.columns:
            out = df.iloc[0:0]
        else:
            value_edge = (df["ovr_pct"] - df["adp_pct"]) >= 0.15
            north_ok = df["north_pct"] >= 0.60
            out = df[value_edge & north_ok & df["vol_ok"]].sort_values(["pos","ovr_pct"], ascending=[True, False])

    out = out.groupby("pos", group_keys=False).head(limit)
    items = _serialize_rows(out)
    return HotListResponse(
        week=META["week"], bucket=bucket,
        criteria={
            "pos": pos or "ALL",
            "elite_cut": "p90 ovr, p85 N, p75 E, p25 S (lower), p70 W" if bucket=="elite" else "",
            "risers_cut": ">= +5 vs base & >=2 weeks" if bucket=="risers" else "",
            "usage_surge_cut": ">= big threshold (routes% or snap_pp)" if bucket=="usage_surge" else "",
            "value_cut": "ovr_pct - adp_pct >= 0.15 & north >= p60" if bucket=="value" else ""
        },
        model_version=META["model_version"],
        inputs_version=META["inputs_version"],
        players=items
    )
```

---

# 4) app.py (wire it up)

```python
# app.py
from fastapi import FastAPI
from hotlist import router, set_weekly_context
import pandas as pd

app = FastAPI()
app.include_router(router)

# Example of setting the weekly context from your ETL:
def boot_with_weekly_frames():
    week = "2025-W02"
    model_version = "ovr-compass-1.0.0"
    inputs_version = "ovr-inputs-2025w02"

    # Load your weekly player frame from storage/cache
    df_weekly = pd.read_parquet("storage/weekly_players_2025W02.parquet")
    change_ranges = pd.read_csv("ovr_inputs/weekly_change_ranges.csv")

    set_weekly_context(df_weekly, change_ranges, week, model_version, inputs_version)

boot_with_weekly_frames()
```

---

# 5) Expected columns in `df_weekly` (your ETL should supply)

* `player_id, name, team, pos`
* `week, base_ovr, current_ovr, weekly_change`
* `north, east, south, west` (0–100 sub-scores)
* `routes, carries` (raw usage to enforce volume floors)
* `delta_snap_pp, delta_routes_pct, delta_carry_share, delta_route_share`
* `persistence_weeks` (optional, if you compute it)
* `reasons` (list or comma-string, we take top 3)
* `confidence` (low/med/high)
* `adp_pct` (0..1) for **value** bucket (optional)

---

# 6) Smoke test (minimal)

Hit:

```
GET /players/hot-list?bucket=elite
GET /players/hot-list?bucket=risers&pos=WR
GET /players/hot-list?bucket=usage_surge&pos=RB
GET /players/hot-list?bucket=value&pos=WR
```

Each should return position-sorted lists with percentiles applied and volume floors enforced.

---

# 7) Tiny helper for the front-end (sort keys)

Use this ordering when rendering lists:

* Primary sort = **current\_ovr** (desc)
* Tie-breakers: **north** (desc) → **east** (desc) → **south** (asc) → **west** (desc)

---

# 8) Gotchas handled

* Percentiles are **per position** to keep TE sane.
* Volume floors prevent 6-route flukes from spiking lists.
* Bye weeks aren’t penalized (your ETL should set `weekly_change = 0`).
* Injury/Q tags can be wired to **halve** positive deltas (see helper for that pattern).

---

If you want me to add a **unit-testable stub** that builds a fake `df_weekly` with a few players (Worthy, MHJ, etc.) and runs all four buckets, I’ll drop it.
